---
title: "python: ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰URLã‚’èª­ã¿è¾¼ã¿ã‚¿ã‚¤ãƒˆãƒ«ã¨åˆã‚ã›ã¦å‡ºåŠ›ã™ã‚‹"
emoji: "ğŸ"
type: "tech"
topics: ["python", "ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"]
published: true
---

chromeã§èª¿ã¹ç‰©ã‚’ã—ãŸå¾Œã«é–‹ã‹ã‚ŒãŸãƒªãƒ³ã‚¯ã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã¾ã¨ã‚ã‚‹ä½œæ¥­ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãŸã‚ã«[Create Link](https://chrome.google.com/webstore/detail/create-link/gcmghdmnkfdbncmnmlkkglmnnhagajbm?hl=ja)ã¨ã„ã†æ‹¡å¼µæ©Ÿèƒ½ã‚’ä½¿ãŠã†ã¨æ€ã£ãŸã®ã§ã™ãŒã€ãªãœã‹ã‚³ãƒ”ãƒ¼ãŒã†ã¾ãã„ã‹ãªã‹ã£ãŸã®ã§pythonã§è‡ªå‹•åŒ–ã—ã¾ã—ãŸã€‚

#### å®Ÿè¡Œã‚¤ãƒ¡ãƒ¼ã‚¸
å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«
```txt:input.txt
https://qiita.com/ika020202/items/5bb39e5bb1645b38d4b8
https://qiita.com/coka__01/items/30716f42e4a909334c9f
```

å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
```txt:output.txt
Flutterã®Riverpodã®Providerç¨®é¡ã®ãƒ¡ãƒ¢ - Qiita|https://qiita.com/ika020202/items/5bb39e5bb1645b38d4b8
[Flutter]ã‚³ãƒ”ãƒšã§ä½¿ãˆã‚‹ï¼ãƒœã‚¿ãƒ³ã®ãƒ‡ã‚¶ã‚¤ãƒ³16ç¨®é¡ã‚’ã¾ã¨ã‚ã¾ã—ãŸ - Qiita|https://qiita.com/coka__01/items/30716f42e4a909334c9f
```

[Create Link](https://chrome.google.com/webstore/detail/create-link/gcmghdmnkfdbncmnmlkkglmnnhagajbm?hl=ja)ã§ã‚ã‚Œã°ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã‹ã‚Œã¦ã„ã‚‹ãƒªãƒ³ã‚¯ã‚’å‹æ‰‹ã«å–å¾—ã—ã‚¿ã‚¤ãƒˆãƒ«ã‚’å‡ºåŠ›ã—ã¦ãã‚Œã‚‹ã®ã§ã™ãŒã€ä»Šå›ã¯ãã“ã¾ã§ã®å®Ÿè£…ã¯è¡Œã£ã¦ã„ã¾ã›ã‚“ã€‚
chromeã§é–‹ã‹ã‚Œã¦ã„ã‚‹å…¨ã¦ã®ãƒªãƒ³ã‚¯ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹ã«ã¯[Copy All Urls](https://chrome.google.com/webstore/detail/copy-all-urls/djdmadneanknadilpjiknlnanaolmbfk?hl=ja)ã‚’ä½¿ã†ã¨æ¥½ã§ã™ã®ã§ã€ã“ã¡ã‚‰ã‹ã‚‰ãƒªãƒ³ã‚¯ã‚’ã‚³ãƒ”ãƒ¼ã—å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ã¿ã¦ãã ã•ã„ã€‚

#### ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰
```py
import requests
from bs4 import BeautifulSoup

input_path = 'input.txt'
output_text_list = []

with open(input_path, 'r') as f:
	file_data = f.readlines()
	for link in file_data:
		link = link.rstrip()
		r = requests.get(link)
		soup = BeautifulSoup(r.text)
		output_text_list.append(soup.find("title").text + '|' + link)

with open('output.txt', 'w') as f:
	f.write('\n'.join(output_text_list))
```

#### è§£èª¬
ä½¿ç”¨ã™ã‚‹requestsã¨BeautifulSoupã‚’importã—ã¾ã™ã€‚
```py
import requests
from bs4 import BeautifulSoup
```

input_pahtã‚’é–‹ãè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ãƒªãƒ³ã‚¯ã‚’èª­ã¿è¾¼ã‚“ã§ã„ãã€ã‚¿ã‚¤ãƒˆãƒ«ã¨åˆã‚ã›ã¦å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆã«å…¥ã‚Œã¦ã„ãã¾ã™ã€‚
```py
with open(input_path, 'r') as f:
	file_data = f.readlines()
	for link in file_data:
		link = link.rstrip()
		r = requests.get(link)
		soup = BeautifulSoup(r.text)
		output_text_list.append(soup.find("title").text + '|' + link)
```

ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚“ã è¡Œãƒ‡ãƒ¼ã‚¿ã®æœ«å°¾ã«ã¯æ”¹è¡Œã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã®ã§ã€rstripé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å‰Šé™¤ã—ã¾ã™ã€‚
```py
link = link.rstrip()
```

ä»Šå›ã¯ã©ã†ã„ã†å½¢å¼ã§ã¾ã¨ã‚ã¦ã„ãã‹æ±ºã‚ã¦ã„ãªã„ã®ã§ã€ä¸€æ—¦'ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«|URL'ã®å½¢ã§ã¾ã¨ã‚ã¦ã„ãã¾ã™ã€‚
åŒºåˆ‡ã‚Šæ–‡å­—ã¯URLã«å«ã¾ã‚Œãªã„æ–‡å­—åˆ—ã§ã‚ã‚‹'|'ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
```py
output_text_list.append(soup.find("title").text + '|' + link)
```

æœ€å¾Œã«ã¾ã¨ã‚ãŸã‚‚ã®ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã—ã¾ã™ã€‚
```py
with open('output.txt', 'w') as f:
	f.write('\n'.join(output_text_list))
```

