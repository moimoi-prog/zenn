---
title: "画像認識で用いるCNNについて解説してみる"
emoji: "🕌"
type: "tech"
topics: []
published: false
---

技術ブログメモ

## はじめに
はじめまして、Branu株式会社の薩間です。
2021年9月にアプリエンジニアとして入社し、「CAREECON for Work 施工管理」のアプリ開発に携わっています。

今回は個人的に勉強している機械学習の中からCNNについて解説し、PythonのKerasで実装してみます。

## 対象の方
- ディープラーニングについてある程度理解しているがCNNについてはよくわからない方
- 畳み込み層やプーリング層がどのような処理を行なっているか知りたい方
- とりあえずCNNのコードを動かしてみたい方


## CNNって何？
- ここに画像を挿入する

CNN(畳み込みニューラルネットワーク:Convolutional Neural Network)とは、ディープニューラルネットワークの入力層と隠れ層の間に「畳み込み層」と「プーリング層」を複数重ねたもののことを指します。
入力値の特徴全体から一部を切り取って学習できるという点から画像認識に強みを持ち、DNNより高い精度で画像データの学習を行うことができます。


## 畳み込み層の働き
畳み込み層は脳の受容野にある神経細胞のひとつである「単純型細胞」をモデルにしています。
単純型細胞は視界のどこにどのような特徴があるかを検出する働きを持っており、畳み込み層ではこの働きをアルゴリズムで再現しています。

畳み込み層では入力された画像に対して特定の特徴を持つフィルター(カーネル)をチャネル数分用意し、それぞれをストライドで指定したマスずつずらしながら照らし合わせ、特徴と存在する位置を検出していき特徴マップを生成します。

特徴が存在する位置を検出できるという点がポイントで、画像などの特徴量の「値」に加えて「位置」も学習する必要があるデータに対する精度は通常のニューラルネットワークよりも高くなります。


## プーリング層の働き
プーリング層は脳の受容野にある神経細胞のひとつである「複雑型細胞」をモデルにしています。
複雑型細胞は視界のどこに特徴が存在していても同じように検出する働きを持っており、プーリング層ではこの働きをアルゴリズムで再現しています。

プーリング層では入力された特徴マップを小さな範囲ごとに分割し、範囲の特徴を示す値(最大値、平均値等)を取り出していき、生成した値を出力値とします。

範囲ごとの特徴を取り出していくという点がポイントで、これにより入力画像がズレていても同じような出力値を生成することができます。

畳み込み層とプーリング層を複数重ねて画像から強い特徴のみを残したデータを生成し、それを隠れ層に渡して学習することで高い精度で学習できるというものがCNNとなります。


## ソースコード
```py
# MNISTによるMLP構築の写経
import keras
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten
from tensorflow.keras.optimizers import Adam

# 画像を用意する
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# 特徴量の範囲を0 ~ 1の範囲に納めるように変換する
x_train = x_train.astype('float32')/255
x_test = x_test.astype('float32')/255

# 出力データをone_hot表現に変形する
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# モデルを構築する
model = Sequential()

# 畳み込み層
model.add(Conv2D(16, (3, 3), padding='same', input_shape=(28, 28, 1), activation='relu'))

# プーリング層
model.add(MaxPooling2D(pool_size=(2, 2))) 

# 畳み込み層
model.add(Conv2D(128, (3, 3), activation='relu'))

# プーリング層
model.add(MaxPooling2D(pool_size=(2, 2)))                

# 畳み込み層
model.add(Conv2D(256, (3, 3), activation='relu'))

# プーリング層
model.add(MaxPooling2D(pool_size=(2, 2)))                

# Dropout ... 全結合層との繋がりを引数の分だけ無効化する
# 過学習を予防するために用いる
model.add(Dropout(0.5))

# Flatten ... n次元の入力値をベクトルに変換する
model.add(Flatten())

# 入力層
# ニューロン数 500, 活性化関数 ReLU
model.add(Dense(units=500, input_shape=(784,), activation='relu'))

# 過学習の予防
model.add(Dropout(0.25))

# 出力層
model.add(Dense(units=10, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# モデルに学習させる
model.fit(x_train, y_train, batch_size=1000, epochs=10, verbose=1, validation_data=(x_test, y_test))

# モデルを評価する
test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
print('損失:', test_loss)
print('評価:', test_accuracy)
```


## 解説
今回はMNISTの手書き文字識別を行いますので、Kerasからimportして読み込みます。
```py
# 画像を用意する
(x_train, y_train), (x_test, y_test) = mnist.load_data()
```


```py
# 特徴量の範囲を0 ~ 1の範囲に納めるように変換する
x_train = x_train.astype('float32')/255
x_test = x_test.astype('float32')/255

# 出力データをone_hot表現に変形する
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
```

```py
# 畳み込み層
model.add(Conv2D(16, (3, 3), padding='same', input_shape=(28, 28, 1), activation='relu'))

# プーリング層
model.add(MaxPooling2D(pool_size=(2, 2)))
```

```py
# Dropout ... 全結合層との繋がりを引数の分だけ無効化する
# 過学習を予防するために用いる
model.add(Dropout(0.5))
```


```py
# Flatten ... n次元の入力値をベクトルに変換する
model.add(Flatten())
```


```py
# 入力層
# ニューロン数 500, 活性化関数 ReLU
model.add(Dense(units=500, input_shape=(784,), activation='relu'))

# 過学習の予防
model.add(Dropout(0.25))

# 出力層
model.add(Dense(units=10, activation='softmax'))
```


```py
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
```


```py
# 損失関数、最適化関数、評価関数
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
```


```py
# モデルに学習させる
model.fit(x_train, y_train, batch_size=1000, epochs=10, verbose=1, validation_data=(x_test, y_test))
```


```py
# モデルを評価する
test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
print('損失:', test_loss)
print('評価:', test_accuracy)
```


## 結果
```bash
Epoch 1/10
60/60 [==============================] - 102s 2s/step - loss: 0.5741 - accuracy: 0.8190 - val_loss: 0.0897 - val_accuracy: 0.9709
Epoch 2/10
60/60 [==============================] - 102s 2s/step - loss: 0.1120 - accuracy: 0.9658 - val_loss: 0.0483 - val_accuracy: 0.9833
Epoch 3/10
60/60 [==============================] - 101s 2s/step - loss: 0.0755 - accuracy: 0.9764 - val_loss: 0.0362 - val_accuracy: 0.9876
Epoch 4/10
60/60 [==============================] - 110s 2s/step - loss: 0.0603 - accuracy: 0.9812 - val_loss: 0.0317 - val_accuracy: 0.9894
Epoch 5/10
60/60 [==============================] - 102s 2s/step - loss: 0.0511 - accuracy: 0.9837 - val_loss: 0.0277 - val_accuracy: 0.9907
Epoch 6/10
60/60 [==============================] - 100s 2s/step - loss: 0.0427 - accuracy: 0.9862 - val_loss: 0.0241 - val_accuracy: 0.9920
Epoch 7/10
60/60 [==============================] - 101s 2s/step - loss: 0.0383 - accuracy: 0.9878 - val_loss: 0.0220 - val_accuracy: 0.9932
Epoch 8/10
60/60 [==============================] - 100s 2s/step - loss: 0.0335 - accuracy: 0.9892 - val_loss: 0.0208 - val_accuracy: 0.9933
Epoch 9/10
60/60 [==============================] - 100s 2s/step - loss: 0.0306 - accuracy: 0.9904 - val_loss: 0.0192 - val_accuracy: 0.9934
Epoch 10/10
60/60 [==============================] - 100s 2s/step - loss: 0.0290 - accuracy: 0.9907 - val_loss: 0.0201 - val_accuracy: 0.9941
損失: 0.020143641158938408
評価: 0.9940999746322632
```

出典
https://www.cis.twcu.ac.jp/~asakawa/MathBio2010/lesson12/